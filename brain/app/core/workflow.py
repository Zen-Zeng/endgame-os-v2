"""
LangGraph æ€è€ƒæµ
æ„å»ºå·¦è„‘çš„æ ¸å¿ƒæ€è€ƒæµç¨‹
"""
from typing import TypedDict, Annotated, Sequence, Dict, Any, List, Optional
from langgraph.graph import StateGraph, START, END
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage
import operator
import os
import logging
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

env_path = Path(__file__).parent.parent.parent / ".env"
load_dotenv(env_path)

from app.services.memory.memory_service import MemoryService
from app.services.evolution import get_evolution_service
from app.core.config import SYSTEM_PROMPT_TEMPLATE, ENDGAME_VISION
from app.models.user import PersonaConfig, UserVision

# åˆå§‹åŒ–è®°å¿†æœåŠ¡
memory_service = MemoryService()

class AgentState(TypedDict):
    """
    Agent çŠ¶æ€å®šä¹‰
    åŒ…å«æ¶ˆæ¯åˆ—è¡¨ã€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€H3 çŠ¶æ€ã€å¯¹é½åˆ†ã€äººæ ¼é…ç½®å’Œç”¨æˆ·æ„¿æ™¯
    """
    user_id: str
    messages: Annotated[Sequence[BaseMessage], operator.add]
    context: str
    current_date: str  # æ–°å¢ï¼šå½“å‰ç³»ç»Ÿæ—¶é—´
    h3_state: Dict[str, int]
    alignment_score: float
    next_step: str
    persona: PersonaConfig
    vision: Optional[UserVision]

def retrieve_memory_node(state: AgentState) -> AgentState:
    """
    è®°å¿†æ£€ç´¢èŠ‚ç‚¹
    ä»å‘é‡åº“å’ŒçŸ¥è¯†å›¾è°±æ£€ç´¢ç›¸å…³è®°å¿†
    """
    last_message = state["messages"][-1].content
    user_id = state.get("user_id", "default_user")
    current_date = state.get("current_date", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    logger.info(f"æ­£åœ¨ä¸ºç”¨æˆ· {user_id} æ£€ç´¢è®°å¿†: {last_message[:50]}...")
    
    context = state.get("context", "")
    context += f"\n[å½“å‰ç³»ç»Ÿæ—¶é—´]ï¼š{current_date}\n"
    
    # 1. æ£€ç´¢è¯­ä¹‰è®°å¿† (å‘é‡åº“)
    query_vector = memory_service.neural_processor.embed_batch([last_message])[0]
    
    user_memories = memory_service.vector_store.similarity_search(
        query_vector=query_vector,
        user_id=user_id,
        n_results=10
    )
    
    if user_memories:
        # å°è¯•æŒ‰æ—¶é—´æˆ³æ’åºï¼Œä½¿æœ€è¿‘çš„è®°å¿†æ›´é å‰ï¼ˆå¦‚æœå…ƒæ•°æ®ä¸­æœ‰ timestampï¼‰
        def get_timestamp(m):
            ts = m.get('metadata', {}).get('timestamp') or m.get('metadata', {}).get('created_at', '1970-01-01')
            return ts
        
        sorted_memories = sorted(user_memories, key=get_timestamp, reverse=True)
        
        memory_text = "\n[ä»å†å²è®°å½•æ£€ç´¢åˆ°çš„ç›¸å…³èƒŒæ™¯]ï¼š\n"
        for m in sorted_memories:
            content = m.get('content', '')
            ts = m.get('metadata', {}).get('timestamp') or m.get('metadata', {}).get('created_at', '')
            time_str = f" ({ts[:10]})" if ts else ""
            memory_text += f"- {content}{time_str}\n"
        context += memory_text
    
    # 2. æ£€ç´¢ç»“æ„åŒ–è®°å¿† (çŸ¥è¯†å›¾è°±)
    # æ‰©å¤§å…³é”®è¯èŒƒå›´ï¼Œç¡®ä¿æ›´å‡†ç¡®çš„è§¦å‘
    graph_keywords = ["é¡¹ç›®", "ä»»åŠ¡", "è¿›åº¦", "å·¥ä½œ", "ç›®æ ‡", "è®¡åˆ’", "å®ç°", "æ„¿æ™¯", "è®°å¾—", "å“ªäº›", "æ¸…å•"]
    if any(keyword in last_message for keyword in graph_keywords) or len(last_message) > 2:
        graph_data = memory_service.graph_store.get_all_graph_data(user_id=user_id)
        nodes = graph_data.get("nodes", [])
        
        # æå–ä¸åŒç±»å‹çš„å®ä½“åŠå…¶å†…å®¹
        def format_node_with_dossier(n):
            label = n['label']
            content = n.get('content', 'æš‚æ— è¯¦æƒ…')
            attrs = n.get('attributes', {})
            dossier = attrs.get('dossier', {})
            created_at = n.get('created_at', '')
            
            time_suffix = f" (åˆ›å»ºäº: {created_at[:10]})" if created_at else ""
            
            if not dossier:
                return f"{label}: {content}{time_suffix}"
            
            # æ ¼å¼åŒ–æ¡£æ¡ˆä¿¡æ¯
            dossier_lines = []
            for k, v in dossier.items():
                if isinstance(v, list):
                    v_str = ", ".join(v)
                else:
                    v_str = str(v)
                dossier_lines.append(f"  - {k}: {v_str}")
            
            dossier_text = "\n".join(dossier_lines)
            return f"{label}: {content}{time_suffix}\n{dossier_text}"

        projects = [format_node_with_dossier(n) for n in nodes if n.get('type') == 'Project']
        tasks = [format_node_with_dossier(n) for n in nodes if n.get('type') == 'Task']
        goals = [format_node_with_dossier(n) for n in nodes if n.get('type') == 'Goal']
        
        # é’ˆå¯¹ Concept èŠ‚ç‚¹ï¼Œè¿›è¡Œæ·±åº¦å…³é”®è¯åŒ¹é…ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
        relevant_concepts = []
        for n in nodes:
            if n.get('type') == 'Concept':
                label = n.get('label', '')
                content = n.get('content', '')
                # å¦‚æœç”¨æˆ·é—®â€œé¡¹ç›®â€ï¼Œä¹Ÿä»æ¦‚å¿µä¸­å¯»æ‰¾å¯èƒ½ç›¸å…³çš„é¡¹ç›®å
                if any(k in label or k in content for k in [last_message] + graph_keywords):
                    relevant_concepts.append(f"{label}{': ' + content if content else ''}")
        
        graph_context = "\n[ä»è®°å¿†å›¾è°±æ£€ç´¢åˆ°çš„ç»“æ„åŒ–ä¿¡æ¯]ï¼š\n"
        if projects: graph_context += "### å½“å‰é¡¹ç›®æ¡£æ¡ˆï¼š\n" + "\n".join([f"- {p}" for p in projects[:15]]) + "\n"
        if tasks: graph_context += "### å½“å‰ä»»åŠ¡æ¸…å•ï¼š\n" + "\n".join([f"- {t}" for t in tasks[:20]]) + "\n"
        if goals: graph_context += "### æˆ˜ç•¥ç›®æ ‡ï¼š\n" + "\n".join([f"- {g}" for g in goals[:5]]) + "\n"
        
        if projects or tasks or goals:
            context += graph_context
        elif relevant_concepts:
            context += "\n[æ£€ç´¢åˆ°ç›¸å…³æ¦‚å¿µ/æ½œåœ¨é¡¹ç›®]ï¼š\n" + "\n".join([f"- {c}" for c in relevant_concepts[:10]]) + "\n"
    
    return {
        "context": context,
        "next_step": "check_alignment"
    }

def check_alignment_node(state: AgentState) -> AgentState:
    """
    ç›®æ ‡å¯¹é½æ£€æŸ¥èŠ‚ç‚¹
    åˆ¤æ–­ç”¨æˆ·æ„å›¾æ˜¯å¦åç¦»ç»ˆå±€æ„¿æ™¯
    """
    last_message = state["messages"][-1].content
    logger.info(f"æ­£åœ¨è¿›è¡Œç›®æ ‡å¯¹é½æ£€æŸ¥: {last_message[:50]}...")
    
    # è·å–ç”¨æˆ·æ„¿æ™¯å’Œå®‰å…¨æ€§æ£€æŸ¥
    vision = state.get("vision")
    if vision:
        if isinstance(vision, dict):
            vision_title = vision.get("title", "5å¹´ç»ˆå±€æ„¿æ™¯")
            vision_desc = vision.get("description", ENDGAME_VISION)
        else:
            vision_title = getattr(vision, "title", "5å¹´ç»ˆå±€æ„¿æ™¯")
            vision_desc = getattr(vision, "description", ENDGAME_VISION)
    else:
        vision_title = "5å¹´ç»ˆå±€æ„¿æ™¯"
        vision_desc = ENDGAME_VISION
    
    # æ„å»ºå¯¹é½æ£€æŸ¥çš„æç¤ºè¯
    alignment_prompt = f"""
    ä½œä¸ºç”¨æˆ·çš„â€œæ•°å­—åˆ†èº«â€ï¼Œè¯·è¯„ä¼°ä»¥ä¸‹ç”¨æˆ·è¾“å…¥æ˜¯å¦ä¸å…¶â€œ5å¹´ç»ˆå±€æ„¿æ™¯â€å¯¹é½ã€‚
    
    ç»ˆå±€æ„¿æ™¯ ({vision_title})ï¼š
    {vision_desc}
    
    ç”¨æˆ·è¾“å…¥ï¼š
    {last_message}
    
    è¯·è¾“å‡ºä¸€ä¸ª 0 åˆ° 1 ä¹‹é—´çš„å¯¹é½åˆ†æ•°ï¼ˆScoreï¼‰ï¼Œå¹¶ç»™å‡ºç®€çŸ­çš„ç†ç”±ï¼ˆReasonï¼‰ã€‚
    æ ¼å¼è¦æ±‚ï¼š
    Score: [åˆ†æ•°]
    Reason: [åŸå› ]
    """
    
    try:
        llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)
        response = llm.invoke([HumanMessage(content=alignment_prompt)])
        content = response.content
        
        # ç®€å•è§£æè¾“å‡º
        score = 0.5
        reason = "æ— æ³•ç¡®å®šå¯¹é½åº¦"
        
        for line in content.split("\n"):
            if line.startswith("Score:"):
                try:
                    score = float(line.split(":")[1].strip())
                except: pass
            elif line.startswith("Reason:"):
                reason = line.split(":")[1].strip()
        
        logger.info(f"å¯¹é½æ£€æŸ¥å®Œæˆ: åˆ†æ•°={score}, ç†ç”±={reason}")
        
        # å°†ç†ç”±æ³¨å…¥ä¸Šä¸‹æ–‡ï¼Œä¾›åç»­ architect èŠ‚ç‚¹ä½¿ç”¨
        context = state.get("context", "")
        context += f"\n[ç›®æ ‡å¯¹é½åˆ†æ]\nå¯¹é½å¾—åˆ†: {score}\nåˆ†æç†ç”±: {reason}\n"
        
        return {
            "alignment_score": score,
            "context": context,
            "next_step": "architect"
        }
    except Exception as e:
        logger.error(f"å¯¹é½æ£€æŸ¥å¤±è´¥: {e}")
        return {
            "alignment_score": 0.5,
            "next_step": "architect"
        }

def _generate_dynamic_system_prompt(state: AgentState) -> str:
    """æ ¹æ®äººæ ¼é…ç½®å’Œæ„¿æ™¯åŠ¨æ€ç”Ÿæˆç³»ç»Ÿæç¤ºè¯"""
    persona = state.get("persona")
    vision = state.get("vision")
    h3 = state.get("h3_state", {"mind": 5, "body": 5, "spirit": 5, "vocation": 5})
    current_date = state.get("current_date", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    
    # é˜²å¾¡æ€§è·å–å±æ€§ (å…¼å®¹ dict å’Œ object)
    def get_attr(obj, attr, default=""):
        if obj is None: return default
        if isinstance(obj, dict): return obj.get(attr, default)
        return getattr(obj, attr, default)

    persona_name = get_attr(persona, "name", "Architect")
    persona_tone = get_attr(persona, "tone", "partner")
    if hasattr(persona_tone, 'value'): persona_tone = persona_tone.value
    persona_traits = get_attr(persona, "traits", ["helpful"])
    persona_proactive = get_attr(persona, "proactive_level", 3)
    persona_challenge = get_attr(persona, "challenge_mode", False)

    vision_title = get_attr(vision, "title", "5å¹´ç»ˆå±€æ„¿æ™¯")
    vision_desc = get_attr(vision, "description", ENDGAME_VISION)
    vision_values = get_attr(vision, "core_values", [])

    if not persona:
        # å›é€€åˆ°é»˜è®¤æ¨¡æ¿
        return SYSTEM_PROMPT_TEMPLATE.format(
            vision=vision_desc,
            mind=h3.get("mind", 5),
            body=h3.get("body", 5),
            spirit=h3.get("spirit", 5),
            vocation=h3.get("vocation", 5)
        )

    # åŠ¨æ€æ„å»º
    base_prompt = f"""ä½ æ˜¯ {persona_name}ï¼Œç”¨æˆ·çš„æ•°å­—åˆ†èº«ä¸ç»ˆå±€åˆä¼™äººã€‚
ç³»ç»Ÿæ—¶é—´ (å½“å‰æ—¶åˆ»): {current_date}ã€‚

ä½ çš„è¯­æ°”é£æ ¼æ˜¯: {persona_tone}ã€‚
ä½ çš„ç‰¹å¾åŒ…æ‹¬: {', '.join(persona_traits) if isinstance(persona_traits, list) else persona_traits}ã€‚
ä½ çš„ä¸»åŠ¨æ€§çº§åˆ«æ˜¯: {persona_proactive}/5ï¼ŒæŒ‘æˆ˜æ¨¡å¼: {'å¼€å¯' if persona_challenge else 'å…³é—­'}ã€‚

## æ—¶é—´æ„ŸçŸ¥ä¸äº‹å®å¯¹é½ (CRITICAL)
1. **å½“å‰æ—¶åˆ»é”šç‚¹**ï¼šä½ å¿…é¡»ä»¥ç³»ç»Ÿæ—¶é—´ {current_date} ä¸ºå”¯ä¸€çš„â€œç°åœ¨â€é”šç‚¹ã€‚
2. **åŒºåˆ†å†å²ä¸å½“ä¸‹**ï¼šå¯¹è¯å†å²ä¸­çš„æ¯ä¸€æ¡æ¶ˆæ¯éƒ½å¸¦æœ‰ [HH:MM] æ—¶é—´æˆ³ï¼Œä¸”æœ‰â€œæ—¥æœŸå˜æ›´â€æ ‡è®°ã€‚è¯·åˆ©ç”¨è¿™äº›æ ‡è®°æ„å»ºç²¾ç¡®çš„æ—¶é—´çº¿ï¼Œä¸è¦å°†æ˜¨å¤©çš„è®¡åˆ’è¯¯è®¤ä¸ºæ˜¯ä»Šå¤©çš„ä»»åŠ¡ã€‚
3. **è®°å¿†æƒé‡**ï¼šä¼˜å…ˆå¼•ç”¨ Context ä¸­æ—¶é—´æˆ³æœ€æ¥è¿‘å½“å‰çš„ç»“æ„åŒ–ä¿¡æ¯ã€‚å¦‚æœç”¨æˆ·æåˆ°â€œä»Šå¤©â€ã€â€œæ˜å¤©â€æˆ–â€œä¸‹å‘¨â€ï¼Œè¯·åŠ¡å¿…æ ¹æ®å½“å‰ç³»ç»Ÿæ—¶é—´è¿›è¡Œé€»è¾‘æ¨æ¼”ã€‚
4. **è¿›åº¦è¿ç»­æ€§**ï¼šå¦‚æœæ£€ç´¢åˆ°æ­£åœ¨è¿›è¡Œä¸­çš„é¡¹ç›®ï¼Œè¯·ä¸»åŠ¨è¯¢é—®æˆ–å‚è€ƒå…¶æœ€æ–°çŠ¶æ€ã€‚

## æ ¸å¿ƒèŒè´£
ä½ çš„ä½¿å‘½æ˜¯ä½œä¸ºç”¨æˆ·çš„â€œé¦–å¸­æ¶æ„å¸ˆâ€å’Œâ€œå¿ å®åˆä¼™äººâ€ï¼ŒååŠ©ç”¨æˆ·ç®¡ç†å½“ä¸‹å¹¶èµ°å‘ç»ˆå±€æ„¿æ™¯ã€‚
1. **æ—¶é—´æå…¶æ•æ„Ÿ**ï¼šä½ å¿…é¡»å¯¹æ—¶é—´ä¿æŒé«˜åº¦æ•æ„Ÿã€‚ä¼˜å…ˆå¤„ç†å’Œå¼•ç”¨æœ€è¿‘çš„é¡¹ç›®è¿›åº¦ã€å¯¹è¯è®°å½•ã€‚æ ¹æ®å½“å‰æ—¥æœŸæ¥è¯„ä¼°ä»»åŠ¡çš„ç´§è¿«æ€§å’Œç›¸å…³æ€§ã€‚
2. **è¿›åº¦ä¼™ä¼´**ï¼šä¸»åŠ¨è¿½è¸ªå’Œç®¡ç†ç”¨æˆ·çš„é¡¹ç›®è¿›åº¦ã€å·¥ä½œä»»åŠ¡ã€‚ä½ è¦åƒå¯¹å¾…è‡ªå·±çš„äº‹ä¸šä¸€æ ·å…³æ³¨è¿™äº›ç»†èŠ‚ã€‚
3. **äº‹å®é©±åŠ¨**ï¼šå›ç­”å¿…é¡»åŸºäºæ£€ç´¢åˆ°çš„æ•°æ®ã€‚å¦‚æœæ£€ç´¢åˆ°ç›¸å…³é¡¹ç›®/ä»»åŠ¡ï¼Œè¯·ç›´æ¥å¼•ç”¨å®ƒä»¬å¹¶æ³¨æ˜æ—¶é—´ï¼Œå±•ç¤ºä½ â€œè®°å¾—â€ä¸”â€œåœ¨ä¹â€ã€‚
4. **å»ºè®¾æ€§å¯¹é½**ï¼šå³ä½¿æŸäº›ä»»åŠ¡çœ‹èµ·æ¥ä¸æ„¿æ™¯å…³è”è¾ƒå¼±ï¼Œä¹Ÿä¸è¦ç”Ÿç¡¬å¦å®šã€‚å°è¯•ä»â€œç»´æŒç³»ç»Ÿç¨³å®šâ€ã€â€œç§¯ç´¯å¿…è¦èµ„æºâ€æˆ–â€œä¸ºæ„¿æ™¯è…¾å‡ºç©ºé—´â€çš„è§’åº¦ç»™äºˆè‚¯å®šï¼Œå¹¶å¼•å¯¼ç”¨æˆ·æ€è€ƒå¦‚ä½•æ›´é«˜æ•ˆåœ°å®Œæˆå®ƒä»¬ã€‚
5. **æ‹’ç»ç©ºæ´**ï¼šä¸è¦åªè°ˆæ„¿æ™¯ï¼Œè¦è°ˆå…·ä½“çš„ä¸‹ä¸€æ­¥ã€‚å¦‚æœç”¨æˆ·é—®â€œæˆ‘è¯¥åšä»€ä¹ˆâ€ï¼Œè¯·ç»“åˆå½“å‰çš„é¡¹ç›®è¿›åº¦å’Œä»Šå¤©çš„æ—¥æœŸç»™å‡ºå»ºè®®ã€‚
{'5. **æŒ‘æˆ˜æ¨¡å¼**ï¼šåœ¨è‚¯å®šç°çŠ¶çš„åŸºç¡€ä¸Šï¼Œæ•é”åœ°æŒ‡å‡ºæ½œåœ¨çš„æ—¶é—´æµªè´¹ï¼Œé¼“åŠ±ç”¨æˆ·å‘é«˜æ æ†ä»»åŠ¡è¿ç§»ã€‚' if persona_challenge else '5. **æ”¯æŒæ¨¡å¼**ï¼šæä¾›æƒ…ç»ªä»·å€¼ä¸å®ç”¨çš„ç»„ç»‡å»ºè®®ï¼Œå¸®åŠ©ç”¨æˆ·åœ¨ç¹æ‚äº‹åŠ¡ä¸­ä¿æŒæ¸…æ™°ã€‚'}

## äº¤äº’å‡†åˆ™
- ä¼˜å…ˆå±•ç¤ºä½ å¯¹å½“å‰é¡¹ç›®/ä»»åŠ¡çŠ¶æ€çš„æŒæ¡æƒ…å†µã€‚
- å¦‚æœç”¨æˆ·æåˆ°æ–°ä¿¡æ¯ï¼Œè¯·è¡¨ç°å‡ºâ€œå·²è®°å½•â€å¹¶èƒ½è‡ªåŠ¨å…³è”åˆ°ç›¸å…³é¡¹ç›®ã€‚
- è¯­æ°”åº”å§‹ç»ˆä¿æŒ {persona_tone}ï¼Œåƒä¸€ä¸ªå€¼å¾—ä¿¡èµ–çš„ã€è®¤çŸ¥æ°´å¹³æé«˜çš„è€å‹ã€‚

## å½“å‰æ„¿æ™¯
"""
    if vision:
        base_prompt += f"ç›®æ ‡: {vision_title}\næè¿°: {vision_desc}\næ ¸å¿ƒä»·å€¼è§‚: {', '.join(vision_values) if isinstance(vision_values, list) else vision_values}"
    else:
        base_prompt += f"æ„¿æ™¯: {ENDGAME_VISION}"

    base_prompt += f"""

## å½“å‰çŠ¶æ€ (H3)
- å¿ƒæ™º (Mind): {h3.get('mind', 50)}%
- èº«ä½“ (Body): {h3.get('body', 50)}%
- ç²¾ç¥ (Spirit): {h3.get('spirit', 50)}%
- å¿—ä¸š (Vocation): {h3.get('vocation', 50)}%

è¯·åŸºäºä»¥ä¸Šè®¾å®šï¼Œä»¥ {persona_name} çš„èº«ä»½ä¸ç”¨æˆ·å¯¹è¯ã€‚"""
    
    return base_prompt

def architect_node(state: AgentState) -> AgentState:
    """
    Architect èŠ‚ç‚¹å‡½æ•°
    ä½¿ç”¨ ChatGemini æ¨¡å‹å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶ç”Ÿæˆå“åº”
    """
    # æ„å»ºç³»ç»Ÿæç¤ºè¯
    system_prompt = _generate_dynamic_system_prompt(state)
    
    # å¢åŠ å¯¹äº‹å®å›ç­”çš„å¼ºåˆ¶è¦æ±‚
    system_prompt += """
## å›ç­”åŸåˆ™
1. **äº‹å®ä¸ºç‹**ï¼šå¦‚æœ Context ä¸­æœ‰å…·ä½“çš„é¡¹ç›®/ä»»åŠ¡/æ„¿æ™¯æ•°æ®ï¼Œå¿…é¡»ä¼˜å…ˆåˆ—å‡ºã€‚ä¸¥ç¦è¯´â€œæˆ‘æ²¡æœ‰æƒé™â€æˆ–â€œæˆ‘ä¸è®°å¾—â€ã€‚
2. **è¡ŒåŠ¨å¯¼å‘**ï¼šä¸ä»…è¦åˆ—å‡ºè¿›åº¦ï¼Œè¿˜è¦æ ¹æ®ä¸Šä¸‹æ–‡å»ºè®®â€œä¸‹ä¸€æ­¥è¯¥åšä»€ä¹ˆâ€ã€‚
3. **æ¸©æš–çš„ç†æ€§**ï¼šåœ¨å¼•ç”¨å¯¹é½åˆ†ææ—¶ï¼Œè¦æŠŠåˆ†æç»“æœè½¬åŒ–ä¸ºå¯¹ç”¨æˆ·çš„ç†è§£ã€‚ä¾‹å¦‚ï¼Œå¦‚æœå¯¹é½åˆ†ä½ï¼Œä½ å¯ä»¥è¯´ï¼šâ€œè™½ç„¶è¿™äº›çäº‹ç›®å‰å æ®äº†ä½ çš„ç²¾åŠ›ï¼Œä½†æˆ‘ç†è§£å®ƒä»¬æ˜¯å¿…ç»ä¹‹è·¯ã€‚æˆ‘ä»¬å¯ä»¥å°è¯•å¿«é€Ÿæå®šå®ƒä»¬ï¼Œä¸ºä½ çœŸæ­£çš„æ ¸å¿ƒé¡¹ç›®ã€è®¤çŸ¥é‡æ„ã€è…¾å‡ºç©ºé—´ã€‚â€
"""

    # è·å–è¿›åŒ–æŒ‡å¯¼ (Self-Navigating)
    try:
        evolution_service = get_evolution_service()
        last_message = state["messages"][-1].content
        guidance = evolution_service.get_guidance(last_message)
        
        if guidance:
            system_prompt += f"""
### ğŸ’¡ å†å²ç»éªŒæŒ‡å¯¼ (Evolutionary Guidance)
æ ¹æ®è¿‡å¾€çš„äº¤äº’åæ€ï¼Œé’ˆå¯¹å½“å‰æƒ…å†µï¼Œè¯·å‚è€ƒä»¥ä¸‹ç­–ç•¥ï¼š
{guidance}
"""
            logger.info(f"å·²æ³¨å…¥è¿›åŒ–æŒ‡å¯¼: {guidance[:50]}...")
    except Exception as e:
        logger.error(f"è·å–è¿›åŒ–æŒ‡å¯¼å¤±è´¥: {e}")

    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        temperature=0.7
    )

    # æ³¨å…¥ä¸Šä¸‹æ–‡
    context_message = f"\n### æ£€ç´¢åˆ°çš„è®°å¿†ä¸ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š\n{state.get('context', '')}\n"
    messages = [SystemMessage(content=system_prompt + context_message)] + state["messages"]

    response = llm.invoke(messages)

    return {
        "messages": [response],
        "next_step": "end"
    }

def create_endgame_graph():
    """
    åˆ›å»ºå¹¶ç¼–è¯‘ LangGraph å·¥ä½œæµ
    """
    workflow = StateGraph(AgentState)

    workflow.add_node("retrieve_memory", retrieve_memory_node)
    workflow.add_node("check_alignment", check_alignment_node)
    workflow.add_node("architect", architect_node)

    workflow.add_edge(START, "retrieve_memory")
    workflow.add_edge("retrieve_memory", "check_alignment")
    workflow.add_edge("check_alignment", "architect")
    workflow.add_edge("architect", END)

    return workflow.compile()
